{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 12 - Text Mining\n",
    "## EXTRA\n",
    "### TFIDF Keywords\n",
    "\n",
    "One interesting way to find useful keywords for a document, corpus, or group of documents in a corpus is to use TFIDF weighting to identify the most 'significant' terms. See below to learn how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda install -c conda-forge scikit-learn --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_news_large_phrased.csv', index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting this specific data's tokens column back to a list\n",
    "df['tokens'] = df['tokens'].apply(lambda token_string: token_string.split('|*|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Keywords\n",
    "Term Frequency Inverse Document Frequency or TFIDF is a scoring system that...\n",
    "- Gives a word a higher score if it occurs frequently in a document...\n",
    "- Buit also weights that score depending on how often it also occurs across the corpus.\n",
    "- Words that occur often in a document, and rarely across the corpus are given higher scores.\n",
    "- Words that occur often in a document and often across the corpus are given lower scores.\n",
    "\n",
    "The result is a scoring system that doesn't just highlight 'frequent' words, but instead highlights significant words.\n",
    "\n",
    "Here we'll use SKlearn's TFIDF Vectorizer to generate these word scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally the Tfidf Vectorizer would do tokenization and preprocessing for us. \n",
    "# As we're passing it pre-processed tokens we can use a dummy function, which simply pretends to\n",
    "# process the text\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is recommended to filter out the extreme ends of the vocab. \n",
    "# The default is any words used less than 5 times and any word that occurs in more than 50% of the corpus.\n",
    "# This can be tweaked depending on how succesful yout model is.\n",
    "\n",
    "tfidf_model = TfidfVectorizer(analyzer=dummy, min_df=5, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train our model by fitting it to our entire corpus of tokens\n",
    "model = tfidf_model.fit(df['tokens'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Document Matrix\n",
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/DTM.png?raw=true\" width=\"300\">\n",
    "\n",
    "We're going to turn our model into a \"term document matrix\".Think of it essentially as a spreadsheet where each row represents a word, and each column a document. The value for each cell is the weighted score for that word, in that document.\n",
    "\n",
    "Sklearn by default creates a space efficient 'sparse' matrix, we use `todense()` to make it a full matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = tfidf_model.transform(df['tokens']).todense()\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix) # we can see the matrix layout\n",
    "print(matrix.shape) # we can ask what the shape of the matrix is (i.e. number of rows and columns)\n",
    "print(len(tfidf_model.get_feature_names()))\n",
    "print(len(df)) # the number of columns should match our document count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets put this matrix into a dataframe and assign the column names the correct words \n",
    "\n",
    "doc_term_matrix = pd.DataFrame(matrix, columns=tfidf_model.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top terms for document 0\n",
    "doc_term_matrix.loc[0].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top terms overall\n",
    "doc_term_matrix.mean().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top terms per query\n",
    "# Here we create our groups by grouping the rows of our original df by the query value\n",
    "# when we iterate over each group we ask which rows in the df are part of this group\n",
    "# these rows will correspond to the same rows in our doc_term_matrix so we select the \n",
    "# appropriate rows using .loc, get the mean score for each word and then sort for the top 10\n",
    "\n",
    "for query, group in df.groupby('query'):\n",
    "    print(f\"****{query}****\")\n",
    "    group_rows = group.index\n",
    "    \n",
    "    print(doc_term_matrix.loc[group_rows].mean().sort_values(ascending=False).head(10))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example of TFIDF\n",
    "Sometimes it is easier to understand these processes on a smaller example to really understand what is going on under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = ['This is my first sentence',\n",
    "          'This is the second',\n",
    "          'I enjoy peas in my sentence peas peas peas',\n",
    "          'This is my first sentence']\n",
    "\n",
    "tokens = [doc.split() for doc in test_corpus]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfVectorizer(analyzer=dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.fit(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = tfidf_model.transform(tokens).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term = doc_term_matrix = pd.DataFrame(matrix, columns=tfidf_model.get_feature_names())\n",
    "doc_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/peas.jpg?raw=true\" align=\"right\" width=\"300\">\n",
    "We can see the weighting in these figures that have a range of 0-1.\n",
    "\n",
    "- 'Peas' has a high weighting in doc 2 because it is frequent in doc 2, but infrequent elsewhere.\n",
    "- 'Sentence' has the same weighting in docs 0 and 3, but lower in 2 despite occuring once in all three, because it is competing against more terms.\n",
    "- 'Second' has an above average score because it is only competing against a few other words, and it doesn't occur anywhere else in the corpus.\n",
    "\n",
    "TFIDF highlights \"significant\" words for two reasons...\n",
    "\n",
    "- It gives higher scores to words that occur frequently within a single document, relative to the amount of other words in a document. \n",
    "    - In a document with only 10 words, and 8 of them are \"Peas\", you would imagine peas to be a word that indicates what that document is about.\n",
    "    - In a document where \"Peas\" occurs 8 times, but there are 10,000 other words, then suddenly Peas doesn't look so significant.\n",
    "\n",
    "\n",
    "- It drags down the scores of words if they exist in many of the documents in the corpus. This gives a sense of context to the significance of words. \n",
    "- If you have a corpus about growing Peas, and every document mentions them, well then no matter how many times the word occurs in an individual document, it is probably not very indicative of what that particular Pea focussed document is about, in the broader context of Pea focussed documents.\n",
    "\n",
    "Peas photo by <a href=\"//commons.wikimedia.org/wiki/User:Atomicbre\" title=\"User:Atomicbre\">Bill Ebbesen</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/3.0\" title=\"Creative Commons Attribution-Share Alike 3.0\">CC BY-SA 3.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=15727721\">Link</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:teaching]",
   "language": "python",
   "name": "conda-env-teaching-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
