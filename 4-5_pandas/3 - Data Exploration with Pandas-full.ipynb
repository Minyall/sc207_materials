{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SC207 - Session 3\n",
    "# Exploring, structuring and visualising data with Pandas\n",
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/python_pandas.jpg?raw=true\" align=\"right\">\n",
    "\n",
    "\n",
    "- A major part of computational social science is the storing, manipulation and reporting of data. \n",
    "- Pandas is a powerful data management library specifically built for these kinds of tasks.\n",
    "- It can handle very large amounts of data whilst remaining quick and responsive.\n",
    "\n",
    "- We will be using Pandas throughout our practical sessions as a general purpose data management tool but this week we will focus on learning its features.\n",
    "\n",
    "[__Pandas Documentation__](http://pandas.pydata.org/pandas-docs/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/spotify.png?raw=true\" align=\"right\" width=150>\n",
    "\n",
    "### The Data\n",
    "\n",
    "Today we will be using two sets of data.\n",
    "\n",
    "1. The first dataset we will use for demonstration purposes is from Spotify. Spotify provides access to some of its data through their API. For this session we will be using data from Spotify, collected from a number of playlists including mixed pop, UK top 50, all out decades etc.\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/RMS_Titanic_3.jpg?raw=true\" align=\"right\" width=150>\n",
    "\n",
    "2. The second dataset, to be used for the exercises, is the Titanic Dataset. A common dataset used for data science courses, the Titanic dataset provides the details of the passengers on the Titanic during its catastrophic last voyage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports\n",
    "Importing modules in python is standard practice. Rather than everyone create their own unique code from scratch every time, modules allow us to integrate code developed by others into our own work. In most instances it is better to use a well supported pre-existing library than to write your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we import the `pandas` module. We could simply use `import pandas` however `as` allows us to use a shorter name.\n",
    "# As social convention many modules are referred to with these short names.\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading Data\n",
    "Often (though not always) you will be importing data from a file into Pandas. Pandas can handle a range of import types...\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/pandas_import.png?raw=true\">\n",
    "\n",
    "[Source - Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/io.html)\n",
    "\n",
    "...some will be familiar to you, others less so.\n",
    "\n",
    "Today's data is stored as a __CSV file__, a common format for storing data in a simple way that can be read by lots of different programs including text readers, Microsoft Excel, etc.\n",
    "\n",
    "We need to provide either the relative or full path to the file so Python knows where in your computer to look. If the file is in the same place as your notebook you can provide the *relative* path which is the file path relative to the notebook. In our case the path is simply `spotify_top_songs.csv`. \n",
    "\n",
    "Whilst you're still learning it is best to just keep all relevant files in the same folder as your notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'spotify_top_songs.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load your saved data as variable songs_df, df being short for DataFrame\n",
    "\n",
    "songs_df = pd.read_csv(filename)\n",
    "type(songs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1187, 12)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get a quick sense of the size of our dataset using .shape\n",
    "# (number of rows, numer of columns)\n",
    "\n",
    "songs_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Viewing your data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 track_id                              track_name  \\\n0  75FEaRjZTKLhTrFGsfMUXR  Running Up That Hill (A Deal With God)   \n1  4Dvkj6JhhA12EX05fT7y2e                               As It Was   \n2  40SBS57su9xLiE1WqkXOVr                          Afraid To Feel   \n3  2KukL7UlQ8TdvpaA7bY3ZJ                           BREAK MY SOUL   \n4  6xGruZOHLs39ZbVccQTuPZ                           Glimpse of Us   \n\n        artists            genre  release_year  explicit  popularity  \\\n0     Kate Bush          art pop          1985     False          96   \n1  Harry Styles              pop          2022     False          94   \n2     LF SYSTEM      ***OOPS!***          2022     False          82   \n3       Beyoncé        dance pop          2022     False          90   \n4          Joji  alternative r&b          2022     False          98   \n\n   duration_ms  danceability  loudness  speechiness playlist_type  \n0       298933         0.629   -13.123          NaN     mixed_pop  \n1       167303         0.520    -5.338       0.0557     mixed_pop  \n2       177524         0.578    -3.929       0.1140     mixed_pop  \n3       278281         0.687    -5.040       0.0826     mixed_pop  \n4       233456         0.440    -9.258       0.0531     mixed_pop  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>track_name</th>\n      <th>artists</th>\n      <th>genre</th>\n      <th>release_year</th>\n      <th>explicit</th>\n      <th>popularity</th>\n      <th>duration_ms</th>\n      <th>danceability</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>playlist_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75FEaRjZTKLhTrFGsfMUXR</td>\n      <td>Running Up That Hill (A Deal With God)</td>\n      <td>Kate Bush</td>\n      <td>art pop</td>\n      <td>1985</td>\n      <td>False</td>\n      <td>96</td>\n      <td>298933</td>\n      <td>0.629</td>\n      <td>-13.123</td>\n      <td>NaN</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4Dvkj6JhhA12EX05fT7y2e</td>\n      <td>As It Was</td>\n      <td>Harry Styles</td>\n      <td>pop</td>\n      <td>2022</td>\n      <td>False</td>\n      <td>94</td>\n      <td>167303</td>\n      <td>0.520</td>\n      <td>-5.338</td>\n      <td>0.0557</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>40SBS57su9xLiE1WqkXOVr</td>\n      <td>Afraid To Feel</td>\n      <td>LF SYSTEM</td>\n      <td>***OOPS!***</td>\n      <td>2022</td>\n      <td>False</td>\n      <td>82</td>\n      <td>177524</td>\n      <td>0.578</td>\n      <td>-3.929</td>\n      <td>0.1140</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2KukL7UlQ8TdvpaA7bY3ZJ</td>\n      <td>BREAK MY SOUL</td>\n      <td>Beyoncé</td>\n      <td>dance pop</td>\n      <td>2022</td>\n      <td>False</td>\n      <td>90</td>\n      <td>278281</td>\n      <td>0.687</td>\n      <td>-5.040</td>\n      <td>0.0826</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6xGruZOHLs39ZbVccQTuPZ</td>\n      <td>Glimpse of Us</td>\n      <td>Joji</td>\n      <td>alternative r&amp;b</td>\n      <td>2022</td>\n      <td>False</td>\n      <td>98</td>\n      <td>233456</td>\n      <td>0.440</td>\n      <td>-9.258</td>\n      <td>0.0531</td>\n      <td>mixed_pop</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .head() shows us the top 5 rows\n",
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                    track_id                  track_name          artists  \\\n1182  5d6ZRqgbz26Sg4bk1oifQw            Blue Suede Shoes     Carl Perkins   \n1183  6pPr1KLZit9FgFNhp7xE5m              Cheek To Cheek  Ella Fitzgerald   \n1184  2k6qpHJsrKCCyvsHv2cPqR                       Diana        Paul Anka   \n1185  6lYeYgSkWh6TZDQy6YZuvG  Just A Gigolo - Remastered      Louis Prima   \n1186  2R7uUQ0Dehu80gsOcydQC9                  Bo Diddley       Bo Diddley   \n\n                genre  release_year  explicit  popularity  duration_ms  \\\n1182    rock-and-roll          1957     False          57       134445   \n1183  adult standards          1956     False           0       351893   \n1184  adult standards          1966     False          56       140520   \n1185  adult standards          1991     False          53       283200   \n1186   acoustic blues          1958     False          53       149013   \n\n      danceability  loudness  speechiness    playlist_type  \n1182         0.548    -7.318       0.0364  all_out_decades  \n1183         0.648   -13.395       0.0883  all_out_decades  \n1184         0.551    -8.490       0.0325  all_out_decades  \n1185         0.525   -11.987       0.0945  all_out_decades  \n1186         0.809   -12.484       0.0574  all_out_decades  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>track_name</th>\n      <th>artists</th>\n      <th>genre</th>\n      <th>release_year</th>\n      <th>explicit</th>\n      <th>popularity</th>\n      <th>duration_ms</th>\n      <th>danceability</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>playlist_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1182</th>\n      <td>5d6ZRqgbz26Sg4bk1oifQw</td>\n      <td>Blue Suede Shoes</td>\n      <td>Carl Perkins</td>\n      <td>rock-and-roll</td>\n      <td>1957</td>\n      <td>False</td>\n      <td>57</td>\n      <td>134445</td>\n      <td>0.548</td>\n      <td>-7.318</td>\n      <td>0.0364</td>\n      <td>all_out_decades</td>\n    </tr>\n    <tr>\n      <th>1183</th>\n      <td>6pPr1KLZit9FgFNhp7xE5m</td>\n      <td>Cheek To Cheek</td>\n      <td>Ella Fitzgerald</td>\n      <td>adult standards</td>\n      <td>1956</td>\n      <td>False</td>\n      <td>0</td>\n      <td>351893</td>\n      <td>0.648</td>\n      <td>-13.395</td>\n      <td>0.0883</td>\n      <td>all_out_decades</td>\n    </tr>\n    <tr>\n      <th>1184</th>\n      <td>2k6qpHJsrKCCyvsHv2cPqR</td>\n      <td>Diana</td>\n      <td>Paul Anka</td>\n      <td>adult standards</td>\n      <td>1966</td>\n      <td>False</td>\n      <td>56</td>\n      <td>140520</td>\n      <td>0.551</td>\n      <td>-8.490</td>\n      <td>0.0325</td>\n      <td>all_out_decades</td>\n    </tr>\n    <tr>\n      <th>1185</th>\n      <td>6lYeYgSkWh6TZDQy6YZuvG</td>\n      <td>Just A Gigolo - Remastered</td>\n      <td>Louis Prima</td>\n      <td>adult standards</td>\n      <td>1991</td>\n      <td>False</td>\n      <td>53</td>\n      <td>283200</td>\n      <td>0.525</td>\n      <td>-11.987</td>\n      <td>0.0945</td>\n      <td>all_out_decades</td>\n    </tr>\n    <tr>\n      <th>1186</th>\n      <td>2R7uUQ0Dehu80gsOcydQC9</td>\n      <td>Bo Diddley</td>\n      <td>Bo Diddley</td>\n      <td>acoustic blues</td>\n      <td>1958</td>\n      <td>False</td>\n      <td>53</td>\n      <td>149013</td>\n      <td>0.809</td>\n      <td>-12.484</td>\n      <td>0.0574</td>\n      <td>all_out_decades</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .tail() shows us the last 5 rows\n",
    "\n",
    "songs_df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                 track_id                              track_name  \\\n0  75FEaRjZTKLhTrFGsfMUXR  Running Up That Hill (A Deal With God)   \n1  4Dvkj6JhhA12EX05fT7y2e                               As It Was   \n2  40SBS57su9xLiE1WqkXOVr                          Afraid To Feel   \n3  2KukL7UlQ8TdvpaA7bY3ZJ                           BREAK MY SOUL   \n4  6xGruZOHLs39ZbVccQTuPZ                           Glimpse of Us   \n5  1PckUlxKqWQs3RlWXVBLw3                         About Damn Time   \n6  02MWAaffLxlfxAUY7c5dvx                              Heat Waves   \n7  0oiv4E896TUTTeQU0cmIui                                 Massive   \n8  4N5s8lPTsjI9EGP7K4SXzB                       Green Green Grass   \n9  1qEmFfgcLObUfQm0j1W2CK                      Late Night Talking   \n\n         artists             genre  release_year  explicit  popularity  \\\n0      Kate Bush           art pop          1985     False          96   \n1   Harry Styles               pop          2022     False          94   \n2      LF SYSTEM       ***OOPS!***          2022     False          82   \n3        Beyoncé         dance pop          2022     False          90   \n4           Joji   alternative r&b          2022     False          98   \n5          Lizzo         dance pop          2022      True          95   \n6  Glass Animals         gauze pop          2020     False          91   \n7          Drake  canadian hip hop          2022     False          79   \n8    George Ezra          folk-pop          2022     False          69   \n9   Harry Styles               pop          2022     False          95   \n\n   duration_ms  danceability  loudness  speechiness playlist_type  \n0       298933         0.629   -13.123          NaN     mixed_pop  \n1       167303         0.520    -5.338       0.0557     mixed_pop  \n2       177524         0.578    -3.929       0.1140     mixed_pop  \n3       278281         0.687    -5.040       0.0826     mixed_pop  \n4       233456         0.440    -9.258       0.0531     mixed_pop  \n5       191822         0.836    -6.305       0.0656     mixed_pop  \n6       238805         0.761    -6.900       0.0944     mixed_pop  \n7       336924         0.499    -6.774       0.0561     mixed_pop  \n8       167613         0.685    -4.413       0.0595     mixed_pop  \n9       177954         0.714    -4.595       0.0468     mixed_pop  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>track_name</th>\n      <th>artists</th>\n      <th>genre</th>\n      <th>release_year</th>\n      <th>explicit</th>\n      <th>popularity</th>\n      <th>duration_ms</th>\n      <th>danceability</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>playlist_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75FEaRjZTKLhTrFGsfMUXR</td>\n      <td>Running Up That Hill (A Deal With God)</td>\n      <td>Kate Bush</td>\n      <td>art pop</td>\n      <td>1985</td>\n      <td>False</td>\n      <td>96</td>\n      <td>298933</td>\n      <td>0.629</td>\n      <td>-13.123</td>\n      <td>NaN</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4Dvkj6JhhA12EX05fT7y2e</td>\n      <td>As It Was</td>\n      <td>Harry Styles</td>\n      <td>pop</td>\n      <td>2022</td>\n      <td>False</td>\n      <td>94</td>\n      <td>167303</td>\n      <td>0.520</td>\n      <td>-5.338</td>\n      <td>0.0557</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>40SBS57su9xLiE1WqkXOVr</td>\n      <td>Afraid To Feel</td>\n      <td>LF SYSTEM</td>\n      <td>***OOPS!***</td>\n      <td>2022</td>\n      <td>False</td>\n      <td>82</td>\n      <td>177524</td>\n      <td>0.578</td>\n      <td>-3.929</td>\n      <td>0.1140</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2KukL7UlQ8TdvpaA7bY3ZJ</td>\n      <td>BREAK MY SOUL</td>\n      <td>Beyoncé</td>\n      <td>dance pop</td>\n      <td>2022</td>\n      <td>False</td>\n      <td>90</td>\n      <td>278281</td>\n      <td>0.687</td>\n      <td>-5.040</td>\n      <td>0.0826</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6xGruZOHLs39ZbVccQTuPZ</td>\n      <td>Glimpse of Us</td>\n      <td>Joji</td>\n      <td>alternative r&amp;b</td>\n      <td>2022</td>\n      <td>False</td>\n      <td>98</td>\n      <td>233456</td>\n      <td>0.440</td>\n      <td>-9.258</td>\n      <td>0.0531</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1PckUlxKqWQs3RlWXVBLw3</td>\n      <td>About Damn Time</td>\n      <td>Lizzo</td>\n      <td>dance pop</td>\n      <td>2022</td>\n      <td>True</td>\n      <td>95</td>\n      <td>191822</td>\n      <td>0.836</td>\n      <td>-6.305</td>\n      <td>0.0656</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>02MWAaffLxlfxAUY7c5dvx</td>\n      <td>Heat Waves</td>\n      <td>Glass Animals</td>\n      <td>gauze pop</td>\n      <td>2020</td>\n      <td>False</td>\n      <td>91</td>\n      <td>238805</td>\n      <td>0.761</td>\n      <td>-6.900</td>\n      <td>0.0944</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0oiv4E896TUTTeQU0cmIui</td>\n      <td>Massive</td>\n      <td>Drake</td>\n      <td>canadian hip hop</td>\n      <td>2022</td>\n      <td>False</td>\n      <td>79</td>\n      <td>336924</td>\n      <td>0.499</td>\n      <td>-6.774</td>\n      <td>0.0561</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4N5s8lPTsjI9EGP7K4SXzB</td>\n      <td>Green Green Grass</td>\n      <td>George Ezra</td>\n      <td>folk-pop</td>\n      <td>2022</td>\n      <td>False</td>\n      <td>69</td>\n      <td>167613</td>\n      <td>0.685</td>\n      <td>-4.413</td>\n      <td>0.0595</td>\n      <td>mixed_pop</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1qEmFfgcLObUfQm0j1W2CK</td>\n      <td>Late Night Talking</td>\n      <td>Harry Styles</td>\n      <td>pop</td>\n      <td>2022</td>\n      <td>False</td>\n      <td>95</td>\n      <td>177954</td>\n      <td>0.714</td>\n      <td>-4.595</td>\n      <td>0.0468</td>\n      <td>mixed_pop</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can specify the number of rows to return\n",
    "\n",
    "songs_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 1\n",
    "\n",
    "Using `songs_df`, view the\n",
    "- top 20 rows\n",
    "- last 30 rows\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                    track_id                  track_name          artists  \\\n1182  5d6ZRqgbz26Sg4bk1oifQw            Blue Suede Shoes     Carl Perkins   \n1183  6pPr1KLZit9FgFNhp7xE5m              Cheek To Cheek  Ella Fitzgerald   \n1184  2k6qpHJsrKCCyvsHv2cPqR                       Diana        Paul Anka   \n1185  6lYeYgSkWh6TZDQy6YZuvG  Just A Gigolo - Remastered      Louis Prima   \n1186  2R7uUQ0Dehu80gsOcydQC9                  Bo Diddley       Bo Diddley   \n\n                genre  release_year  explicit  popularity  duration_ms  \\\n1182    rock-and-roll          1957     False          57       134445   \n1183  adult standards          1956     False           0       351893   \n1184  adult standards          1966     False          56       140520   \n1185  adult standards          1991     False          53       283200   \n1186   acoustic blues          1958     False          53       149013   \n\n      danceability  loudness  speechiness    playlist_type  \n1182         0.548    -7.318       0.0364  all_out_decades  \n1183         0.648   -13.395       0.0883  all_out_decades  \n1184         0.551    -8.490       0.0325  all_out_decades  \n1185         0.525   -11.987       0.0945  all_out_decades  \n1186         0.809   -12.484       0.0574  all_out_decades  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>track_name</th>\n      <th>artists</th>\n      <th>genre</th>\n      <th>release_year</th>\n      <th>explicit</th>\n      <th>popularity</th>\n      <th>duration_ms</th>\n      <th>danceability</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>playlist_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1182</th>\n      <td>5d6ZRqgbz26Sg4bk1oifQw</td>\n      <td>Blue Suede Shoes</td>\n      <td>Carl Perkins</td>\n      <td>rock-and-roll</td>\n      <td>1957</td>\n      <td>False</td>\n      <td>57</td>\n      <td>134445</td>\n      <td>0.548</td>\n      <td>-7.318</td>\n      <td>0.0364</td>\n      <td>all_out_decades</td>\n    </tr>\n    <tr>\n      <th>1183</th>\n      <td>6pPr1KLZit9FgFNhp7xE5m</td>\n      <td>Cheek To Cheek</td>\n      <td>Ella Fitzgerald</td>\n      <td>adult standards</td>\n      <td>1956</td>\n      <td>False</td>\n      <td>0</td>\n      <td>351893</td>\n      <td>0.648</td>\n      <td>-13.395</td>\n      <td>0.0883</td>\n      <td>all_out_decades</td>\n    </tr>\n    <tr>\n      <th>1184</th>\n      <td>2k6qpHJsrKCCyvsHv2cPqR</td>\n      <td>Diana</td>\n      <td>Paul Anka</td>\n      <td>adult standards</td>\n      <td>1966</td>\n      <td>False</td>\n      <td>56</td>\n      <td>140520</td>\n      <td>0.551</td>\n      <td>-8.490</td>\n      <td>0.0325</td>\n      <td>all_out_decades</td>\n    </tr>\n    <tr>\n      <th>1185</th>\n      <td>6lYeYgSkWh6TZDQy6YZuvG</td>\n      <td>Just A Gigolo - Remastered</td>\n      <td>Louis Prima</td>\n      <td>adult standards</td>\n      <td>1991</td>\n      <td>False</td>\n      <td>53</td>\n      <td>283200</td>\n      <td>0.525</td>\n      <td>-11.987</td>\n      <td>0.0945</td>\n      <td>all_out_decades</td>\n    </tr>\n    <tr>\n      <th>1186</th>\n      <td>2R7uUQ0Dehu80gsOcydQC9</td>\n      <td>Bo Diddley</td>\n      <td>Bo Diddley</td>\n      <td>acoustic blues</td>\n      <td>1958</td>\n      <td>False</td>\n      <td>53</td>\n      <td>149013</td>\n      <td>0.809</td>\n      <td>-12.484</td>\n      <td>0.0574</td>\n      <td>all_out_decades</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code for exercise 1 in this cell\n",
    "\n",
    "songs_df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# QUESTION\n",
    "# What is the name of the song in the very last row of the dataframe? Assign the name as a string to the answer variable\n",
    "\n",
    "answer =\n",
    "\n",
    "if answer.lower() == songs_df.iloc[-1,1].lower():\n",
    "    print(f'Correct!')\n",
    "else:\n",
    "    print('Incorrect - Try again')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Describing your DataFrame\n",
    "<img src=\"https://pandas.pydata.org/docs/_images/01_table_dataframe.svg\" title='Pandas DataFrame' width=\"400\" height=\"200\"/>\n",
    "\n",
    "DataFrames are like big Excel spreadsheets. They have...\n",
    "\n",
    "- Rows\n",
    "- Columns\n",
    "\n",
    "...and `values` which is the data inside the cells of your spreadsheet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['track_id', 'track_name', 'artists', 'genre', 'release_year',\n       'explicit', 'popularity', 'duration_ms', 'danceability', 'loudness',\n       'speechiness', 'playlist_type'],\n      dtype='object')"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see a list of our columns...\n",
    "songs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "RangeIndex(start=0, stop=1187, step=1)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the row index, i.e. the row labels\n",
    "\n",
    "songs_df.index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['75FEaRjZTKLhTrFGsfMUXR',\n        'Running Up That Hill (A Deal With God)', 'Kate Bush', ...,\n        -13.123, nan, 'mixed_pop'],\n       ['4Dvkj6JhhA12EX05fT7y2e', 'As It Was', 'Harry Styles', ...,\n        -5.338, 0.0557, 'mixed_pop'],\n       ['40SBS57su9xLiE1WqkXOVr', 'Afraid To Feel', 'LF SYSTEM', ...,\n        -3.929, 0.114, 'mixed_pop'],\n       ...,\n       ['2k6qpHJsrKCCyvsHv2cPqR', 'Diana', 'Paul Anka', ..., -8.49,\n        0.0325, 'all_out_decades'],\n       ['6lYeYgSkWh6TZDQy6YZuvG', 'Just A Gigolo - Remastered',\n        'Louis Prima', ..., -11.987, 0.0945, 'all_out_decades'],\n       ['2R7uUQ0Dehu80gsOcydQC9', 'Bo Diddley', 'Bo Diddley', ...,\n        -12.484, 0.0574, 'all_out_decades']], dtype=object)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the DataFrame values\n",
    "\n",
    "songs_df.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `.info()` method gives us an overview of our DataFrame, including...\n",
    "- A summary of the index labels\n",
    "- Information the columns\n",
    "- a 'Non-Null' Count. i.e. how many 'cells' in the column have a value in them.\n",
    "- The type (Dtype) of values that column holds.\n",
    "    - Integer (int64) - e.g. 5\n",
    "    - Float (float64)- e.g. 5.3\n",
    "    - Boolean (bool) - e.g. True / False\n",
    "    - Other (object) - Usually a string, but can also be any python object e.g. lists, dictionaries, classes.\n",
    "- A summary of how much computer memory the data needs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1187 entries, 0 to 1186\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   track_id       1187 non-null   object \n",
      " 1   track_name     1187 non-null   object \n",
      " 2   artists        1187 non-null   object \n",
      " 3   genre          1187 non-null   object \n",
      " 4   release_year   1187 non-null   int64  \n",
      " 5   explicit       1187 non-null   bool   \n",
      " 6   popularity     1187 non-null   int64  \n",
      " 7   duration_ms    1187 non-null   int64  \n",
      " 8   danceability   1187 non-null   float64\n",
      " 9   loudness       1187 non-null   float64\n",
      " 10  speechiness    1186 non-null   float64\n",
      " 11  playlist_type  1187 non-null   object \n",
      "dtypes: bool(1), float64(3), int64(3), object(5)\n",
      "memory usage: 103.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# An informative overview of our DataFrame\n",
    "\n",
    "songs_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Accessing columns and rows"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Accessing columns\n",
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/01_table_series.svg?raw=true\" title='Pandas DataFrame'/>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# often we want to access an individual series (column) of the Dataframe, this is done using a 'key' similar to a dictionary\n",
    "\n",
    "df['track_name']\n",
    "\n",
    "# Note that in Jupyter if there is too much data to display \n",
    "# it provides a condensed version - the first and last 30 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We can also select a subset of columns by providing a list of column names as the key.\n",
    "\n",
    "subset = ['track_name','artists','genre']\n",
    "\n",
    "df[subset].head() # use .head() just to keep it tidier to view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Most of the time you will be working primarily with entire Series or subsets of the data rather than drilling down to individual rows, but it is useful to know it is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If we want a specific value from a specific row we provide the column name to .loc\n",
    "# or the column index position to .iloc as well...\n",
    "\n",
    "print(throwaway_df.iloc[1,2])\n",
    "print(throwaway_df.loc[#track name as string here# ,'artists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# you can also provide the column index/name as a seperate key that accesses the result.\n",
    "print(throwaway_df.iloc[1][2])\n",
    "print(throwaway_df.loc['Last Christmas']['artists'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# *Exercises*\n",
    "## Loading and Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Your dataset for the exercises is `titanic.csv`. Load the dataset as a Pandas Dataframe \n",
    "# and assign it to the variable `titanic`\n",
    "\n",
    "titanic = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2. How many rows are there in the dataset? Work out your answer in this cell, and check it in the cell below.\n",
    "\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2a. Assign your answer to the variable `num_records`\n",
    "\n",
    "num_records = 887\n",
    "\n",
    "assert num_records == titanic.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3. What are the ages of the last 5 people in the dataset? \n",
    "\n",
    "titanic.tail()['Age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3a. Once you have your answer make a list called last_5_ages.\n",
    "\n",
    "last_5_ages = [27,19,7,26,32]\n",
    "\n",
    "\n",
    "assert pd.np.mean(last_5_ages) == 22.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4a. Set the index of `titanic` to use the 'Name' column and assign the newly arranged dataframe to `titanic_by_name`\n",
    "\n",
    "titanic_by_name = titanic.set_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4b. Using your `titanic_by_name` dataframe, \n",
    "# locate the row for 'Mr. Howard Hugh Williams' and assign \n",
    "# his age to the variable `age` and the fare he paid to `fare`.\n",
    "\n",
    "\n",
    "\n",
    "age = titanic_by_name.loc['Mr. Howard Hugh Williams','Age']\n",
    "fare = titanic_by_name.loc['Mr. Howard Hugh Williams','Fare']\n",
    "\n",
    "\n",
    "assert(fare / age == 0.28750000000000003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Data Cleaning\n",
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/DC_cleaning_data.png?raw=true\" align=\"right\" width=150 href=https://www.datacamp.com/courses/cleaning-data-in-python>\n",
    "\n",
    "\n",
    "\n",
    "- Depending on how you sourced your data, it may have missing values, duplicates or anomalies. \n",
    "\n",
    "- There are a number of techniques we can use to handle these issues. The theory of handling missing data is itself a big topic particularly in Quantitative methods and cannot be covered in great detail here.\n",
    "\n",
    "- More information can be found in the DataCamp course ['Cleaning Data with Python'](https://www.datacamp.com/courses/cleaning-data-in-python). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The first steps when reviewing any new data should be to get a bird-eye view. \n",
    "# There are a few simple methods built into pandas that can help us.\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`.info()` tells us how many rows are in the dataframe, what the column names are, and how many filled values each column has.\n",
    "\n",
    "This quick overview tells us that some have missing values, and a range of data types.\n",
    "\n",
    "- object = often a column of strings, lists or a dictionaries but can be any data object.\n",
    "\n",
    "- bool = Boolean True or False column.`\n",
    " \n",
    "- int64 = integers\n",
    " \n",
    "- float64 = floats\n",
    "\n",
    "Other notable types which we'll cover later include...\n",
    "\n",
    "- category\n",
    "\n",
    "- datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`.describe()` provides a very quick and dirty way to get some insights into the numerical columns in your data covering...\n",
    "- Count of records\n",
    "- Mean value\n",
    "- Standard Deviation\n",
    "- Minimum Value\n",
    "- 25th / 50th / 75th percentiles\n",
    "- Maximum Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You may already be getting a sense of how DataFrames rely a lot on methods built in to the DataFrame object. Pandas has A LOT of methods. You will find youself referring to [the documentation](https://pandas.pydata.org/pandas-docs/stable/) and Cheat Sheets often when you first start. This is normal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If we look at our data we can see that 'danceability' looks like a float, but it didn't turn up in the summary statistics above..\n",
    "# Let's check it.\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we can see the type for this column is object rather than float.\n",
    "# this might cause problems later because it's being treated\n",
    "# as a string, not a number.\n",
    "df['danceability'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We can do this by exchanging our current series df['danceability'] for a version of df['danceability'] that \n",
    "# has been transformed into float type data.\n",
    "# We do this using the method .astype()\n",
    "\n",
    "df['danceability'] = df['danceability'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now if we check our .info() again we can see the type of the genre series has changed.\n",
    "# reassigning a new series to df['genre'] is a permanent change to the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# It's also worth checking for duplicate data. Spotify provides a unique id number for every track which can be helpful in our case.\n",
    "# Pandas has the .duplicated() and .drop_duplicates() methods for this very issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We can see if there are duplicates using .duplicated() which creates a boolean 'filter' for our data..\n",
    "# We'll cover these in more detail in the next section.\n",
    "\n",
    "dupe_filter = df.duplicated(subset=['track_id'])\n",
    "df[dupe_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We could even test this by manually looking for those tracks. \n",
    "# Remember when we set our index to be the track name?\n",
    "\n",
    "# by doing our operation without assigning it to a variable we can \n",
    "# just view the result without necessarily storing it.\n",
    "# chaining methods allows us to achieve this with one line. Think through each stage of the chain.\n",
    "# What does each stage produce and pass on to the next method?\n",
    "\n",
    "df.set_index('track_name').loc[#Track name here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# let's drop those duplicates. We also need to reset the index after because .drop_duplicates() will \n",
    "# remove rows leaving us with gaps in our index - e.g. 1,2,4,5,6,8,10.\n",
    "# Again we can achieve this by chaining together the methods.\n",
    "\n",
    "df = df.drop_duplicates(subset=['track_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lets check how much data we have left\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We might also be concerned about missing data. \n",
    "# \"Speechiness\" has one less value than all the other columns. This inidcates that one row has a missing value\n",
    "# We can locate this by making a filter using .isna()\n",
    "\n",
    "missing_filter = df['speechiness'].isna()\n",
    "df[missing_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We could replace this value with something... perhaps based on the average speechiness of the genre?\n",
    "# but as it is only one record we'll just drop it from analysis using .dropna()\n",
    "\n",
    "# dropna requires the subset (the columns we're basing our selections on, to be a list)\n",
    "# we say axis = 'index' to say drop rows that have a missing value in speechiness\n",
    "# if we say axis='column' it will drop the entire speechiness column if there is a single missing value!\n",
    "df = df.dropna(subset=['speechiness'], axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sometimes even if Pandas doesn't THINK there is missing data, depending on how the data was created it could still be missing.\n",
    "# Whilst df.info() seems to indicate all is well there is an oddity with our 'genre' column.\n",
    "# for data like our genre column we can use value counts to count the number of instances of different genres\n",
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It looks like whoever generated the data decided to put `***OOPS!***` in as a value if the genre wasn't available.\n",
    "Unfortunately as that is a string like all the other genres, Pandas doesn't know any different.\n",
    "In order for Pandas to understand that it is missing data, we need to replace it with a special object called a NaN.\n",
    "\n",
    "We can get one of these NaN's using Pandas `pd.np.nan` and using the `.replace()` method replace all the `***OOPS!***` with `pd.np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['genre'] = df['genre'].replace(to_replace='***OOPS!***', value=pd.np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# lets save this dataset now it's been cleaned\n",
    "\n",
    "df.to_csv('cleaned_spotify_top_songs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# *Exercises*\n",
    "## *Data Cleaning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Load in the file 'titanic_to_clean.csv' using .read_csv and assign to the variable titanic. Examine the info().\n",
    "\n",
    "titanic = pd.read_csv('titanic_to_clean.csv',)\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1b. Our first issue is the missing data for the fare column. \n",
    "# Use .dropna() providing the 'Fare' column as the subset. Assign the result to\n",
    "# `titanic` to overwrite it.\n",
    "\n",
    "titanic = titanic.dropna(subset=['Fare'])\n",
    "\n",
    "\n",
    "\n",
    "assert titanic.shape[0] == 853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2a Let's check the 'Survived' column to see what it looks like.\n",
    "# Count the number of each value in 'Survived' to get an overall picture of the values used.\n",
    "titanic['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2b. We should only have two categories 0 and 1 to indicate if the individual survived. \n",
    "# Replace any of the values in 'Survived' that are neither a 0 nor 1, with a nan object.\n",
    "\n",
    "titanic['Survived'] = titanic['Survived'].replace(3, pd.np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2c. How many non null values are there in the 'Survived' column now?\n",
    "# Assign your answer to `survived_non_null`\n",
    "\n",
    "survived_non_null = 831\n",
    "\n",
    "assert survived_non_null == titanic.Survived.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2d. Drop the rows that have now have null values in the 'Survived' column\n",
    "\n",
    "titanic.dropna(subset=['Survived'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2e. Finally it would make more sense for us to make the 'Survived' column a Boolean column (True/False)\n",
    "# Pandas will work out that 0 is False whilst 1 is True if we convert it to boolean. Do this now.\n",
    "titanic['Survived'] = titanic['Survived'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3a. Check for any duplicate records. What column do you think would be best to use for the subset?\n",
    "\n",
    "duplicate_filter = titanic.duplicated(subset=['Name'])\n",
    "titanic[duplicate_filter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "titanic = titanic.drop_duplicates(subset=['Name'])\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3b. Finally drop the duplicate records, check how many records you have in your cleaned dataset, \n",
    "# and assign the value to `final_countdown`.\n",
    "\n",
    "final_countdown = 815\n",
    "\n",
    "assert final_countdown == titanic.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.Filtering our Data\n",
    "\n",
    "Filtering Data allows you to select portions of your dataset based on particular conditions, such as all the tracks of a particular genre, or all tracks under a particular duration, or selecting tracks with a particular word in their name.\n",
    "\n",
    "Filtering uses a particular syntax...\n",
    "\n",
    "`df[filter_rule]`\n",
    "\n",
    "We already used this when we showed all the records that had duplicates in our data...\n",
    "\n",
    "    dupe_filter = df.duplicated(subset=['track_id'])\n",
    "    df[dupe_filter]\n",
    "\n",
    "The rule that we use within the brackets can be relatively simple or complex depending on the kinds of queries we have.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reload our cleaned data\n",
    "\n",
    "df = pd.read_csv('cleaned_spotify_top_songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lets see what a filter is doing first...\n",
    "\n",
    "df['popularity'] > 90\n",
    "\n",
    "# We can see that the conditional statement creates a new series that has evaluated \n",
    "# whether the statement is True or False for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If we place this series inside the square brackets of a call to our df variable \n",
    "# it acts as a filter, showing only those rows that have a value of True.\n",
    "\n",
    "pop_filter = df['popularity'] > 90 # same statement as above assigned to a variable.\n",
    "\n",
    "high_pop = df[pop_filter]\n",
    "high_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We can filter any way that we can create a conditional statement and we don't necessarily need to assign the filter rule to another variable first...\n",
    "\n",
    "df[df['explicit'] == False].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We can combine conditional statements with...\n",
    "# & (and)\n",
    "# | (or) - note this is a vertical 'pipe' not an I\n",
    "\n",
    "# Perhaps we want all explicit tracks with a popularity above 90\n",
    "\n",
    "explicit_over_90 = (df['explicit'] == True) & (df['popularity'] > 90)\n",
    "\n",
    "df[explicit_over_90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We can use the | OR operator to get the very highest and very lowest in popularity\n",
    "\n",
    "high_low = (df['popularity'] >90) | (df['popularity'] < 10)\n",
    "df[high_low]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Creating New Data Combinations\n",
    "\n",
    "Pandas allows you to quickly make new data series in your DataFrame, either by providing the values yourself, or by combining your existing data. Unlike filtering to create particular views on the data, these operations add the new data to the DataFrame stored in memory. If you want to keep the columns permanently you'll need to save the data which is covered under 'Exporting'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First we need to create our rule and to understand this we need to understand 'Broadcasting'.\n",
    "\n",
    "# Pandas relies on 'broadcasting', which is the ability to apply an operation to\n",
    "# all values in a series or entire dataframe at the same time. Rarely is it necessary to loop over the\n",
    "# rows to make changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# A simple example would be just adding a new column with a single value...\n",
    "\n",
    "df['source'] = 'Spotify'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# However we normally would want different values for different rows\n",
    "\n",
    "# Say we wanted to change our 'duration' column from miliseconds to seconds to make it more meaningful to us.\n",
    "# The conversion from miliseconds to seconds is to divide by 1000.\n",
    "\n",
    "# We can do this in one line and make this a new column...\n",
    "\n",
    "df['duration_s'] = df['duration_ms'] //1000\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Perhaps we wanted to make a new value by dividing a song's danceability by its speechiness, perhaps believing that\n",
    "# the most danceable songs are non-vocal.\n",
    "\n",
    "# We can add this to the Dataframe by assigning it a column name. \n",
    "\n",
    "df['pure_danciness'] = df['danceability'] / df['speechiness']\n",
    "df.sort_values('pure_danciness', ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Assigning it to a new variable creates a seperate independent series that isn't in the dataframe.\n",
    "# Useful if you don't need the series in the DataFrame.\n",
    "\n",
    "new_score = df['danceability'] / df['speechiness']\n",
    "print(type(new_score))\n",
    "new_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Broadcasting also works with string operations....\n",
    "\n",
    "combi_artist_genre = df['artists'] + ' - ' + df['genre']\n",
    "combi_artist_genre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Visualising\n",
    "Pandas has a range of built in quick visualisation options, accessed through the `.plot()` method. They are built on top of another library called `matplotlib`. This is a very large library in Python which we won't cover much here, but it is key to understand the Pandas uses matplotlib, because you can tweak Pandas visuals using matplotlib commands.\n",
    "\n",
    "However `Seaborn` is a visualisation library that has much more flexibility and is easier to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We'll import maptplotlib's python library here to use it to tweak our plots\n",
    "\n",
    "import matplotlib.pyplot as plt # this is the conventional way to import matplotlib\n",
    "import seaborn as sns # and this is the conventional way to import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lets investigate ages for the titanic to demonstrate basic Pandas plotting\n",
    "\n",
    "\n",
    "\n",
    "titanic['Age'].plot(kind='hist', # There are many kinds of plot we can use built into Pandas\n",
    "                    title='Distribution of Ages of Passengers on the Titanic', #Allows us to set the title\n",
    "                    figsize=(6,4)) # we can also adjust the size (h,v)\n",
    "\n",
    "# we can also relabel the x-axis but we need to use matplotlib to do this\n",
    "plt.xlabel('Age')\n",
    "# and to cleanly display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.plot(kind='scatter',y='popularity',x='speechiness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Seaborn Examples\n",
    "Seaborn allows us to easily split the data up by categories when visualising. Pandas can be used for this but it is much more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=titanic, x='Age', y='Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Scatter plot with hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=titanic, x='Age', y='Fare', hue='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Line Plot with hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=titanic, x='Age',y='Fare', hue='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Box plot with hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxenplot(data=titanic, x='Sex',y='Age',hue='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(titanic['Age'],kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Swarm Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.swarmplot(data=titanic, x='Pclass', y='Fare', hue='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Joint plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data=titanic, x='Age', y='Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data=titanic, hue='Survived',vars=['Fare','Age', 'Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Grouping Data\n",
    "\n",
    "`.groupby()` is a convenient method of spliting up the data, applying an operation and then combining the results of the seperate operations.\n",
    "\n",
    "Let's pose a question - Are there differences between explicit and non-explicit songs? With `.groupby()` and `.describe()` we can examine this quite quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# by calling `.groupby()` on our dataframe, and providing the column we want to group on,\n",
    "# we create a `groupby` object.\n",
    "\n",
    "groups = df.groupby('explicit')\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we'll aggregate the results by taking the .mean() of all the numerical columns\n",
    "# before we can view the data we need to say how we're going to 'aggregate' or summarise the data together.\n",
    "\n",
    "# here we take the mean or the average of the values\n",
    "groups.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If we would prefer the columns and the rows to be swapped, we can .transpose()\n",
    "\n",
    "groups.mean().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "groups.mean().transpose().loc['popularity'].plot(kind='bar', title='Popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# You can use Groupby to group on multiple variables\n",
    "\n",
    "titanic.groupby(['Pclass','Sex']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#.agg is a method that lets us specify exactly what we want each column to do\n",
    "# we give it a dictionary where the key is the column name and the value is the aggregation approach.\n",
    "# pandas has built in functions so we just have to provide the names as strings.\n",
    "\n",
    "aggregation_rules = {'Age':'mean','Survived':'sum','Fare':'mean', 'Name':'count'}\n",
    "\n",
    "grouped_titanic = titanic.groupby(['Pclass','Sex']).agg(aggregation_rules)\n",
    "grouped_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the result of a groupby is another Dataframe, \n",
    "# so we can carry on using it like normal\n",
    "type(grouped_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# lets rename the columns to make them more reflective of the new values\n",
    "rename_rules = {'Age':'average_age',\n",
    "               'Survived':'n_survivors',\n",
    "               'Fare': 'average_fare',\n",
    "                'Name':'n_passengers'}\n",
    "\n",
    "grouped_titanic = grouped_titanic.rename(columns=rename_rules)\n",
    "grouped_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# lets make a new column to determine the percentage of survivors per group\n",
    "\n",
    "grouped_titanic['pct_survivors'] = (grouped_titanic['n_survivors'] / grouped_titanic['n_passengers']) *100\n",
    "grouped_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# a simple way to plot this would be to use pandas built in bar chart\n",
    "grouped_titanic['pct_survivors'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grouped_titanic_to_plot = grouped_titanic.reset_index() #resetting removes the 'multi-index'\n",
    "grouped_titanic_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=grouped_titanic_to_plot, x='Pclass', y='pct_survivors', hue='Sex', dodge=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='export'></a>\n",
    "## 6 - Exporting Data\n",
    "You may want to export your data, or a reshaped version of it, for use in other applications. Pandas can export to a range of data formats including CSV, Excel, Stata, HTML, JSON and others.\n",
    "\n",
    "See: https://pandas.pydata.org/pandas-docs/stable/api.html#id12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Our grouped titanic table makes a good candidate\n",
    "grouped_titanic_to_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grouped_titanic_to_plot.to_excel('our_export.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# *Exercises*\n",
    "## *Grouping and Visualising*\n",
    "\n",
    "In this exercise we are going to explore the differences between the different playlist types in our Spotify dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#1.  First load your cleaned_spotify_top_songs.csv as df\n",
    "\n",
    "df = pd.read_csv('cleaned_spotify_top_songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Using a Seaborn Pairplot (Histogram), visualise the relationships between release year\n",
    "# and popularity and colour by playlist_type, for all songs released after 2000.\n",
    "# Tip. You'll need to filter the df using standard pandas filtering, either beforehand or when you pass it to the pairplot\n",
    "\n",
    "\n",
    "sns.pairplot(data=df[df['release_year'] >=2000], vars=['release_year','popularity'], hue='playlist_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Now group the dataframe by 'playlist_type' and aggregate the values so that it returns the average (or mean) values for all columns\n",
    "# Do this in a single line.\n",
    "\n",
    "# Which playlist, on average, features the most popular songs?\n",
    "df.groupby('playlist_type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4 create a new table by first grouping on release_year and then use the .agg method to aggregate just the 'explicit' column using mean\n",
    "# assign the new series to the variable avg_explicit_year\n",
    "# tip, you'll need to reset the index to make the next step easier\n",
    "\n",
    "avg_explicit_year = df.groupby('release_year').agg({'explicit':'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Now using a seaborn lineplot, examine whether songs have become more explicit over time.\n",
    "sns.lineplot(data=avg_explicit_year, x='release_year', y='explicit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Using broadcasting create a new boolean column where each row is True if \n",
    "# the song has a popularity greater than or equal to 90.\n",
    "# name the column 'top_song'\n",
    "\n",
    "df['top_song'] = df['popularity'] >= 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 6. Use a boxplot to explore the relationship between three dimensions of the data, top_song, danceability, and explicit.\n",
    "# Tip: x and y will provide you two dimensions, how might you add a third?\n",
    "\n",
    "sns.boxplot(data=df, x='top_song', y='danceability', hue='explicit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now  group the df using 'release_year' and 'playlist_type' and aggregate using the mean\n",
    "# assign the result to df_year_avg. Don't forget to reset your index\n",
    "\n",
    "df_year_avg = df.groupby(['release_year','playlist_type']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Finally answer these questions?\n",
    "\n",
    "# What was the average popularity for non-explicit songs in 2019? # this can be answered using one line of code\n",
    "# How does this compare all songs in our sample in or after 2010? - Demonstrate this using a visualisation. # this may need two lines\n",
    "\n",
    "df.groupby(['release_year','explicit']).mean().loc[2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "to_plot = df.groupby(['release_year','explicit']).mean().reset_index()\n",
    "sns.lineplot(data=to_plot[to_plot['release_year'] >= 2000], x='release_year', y='popularity', hue='explicit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}