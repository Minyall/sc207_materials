{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SC207 - Session 7\n",
    "# APIs - Exploring and Summarising Twitter Data\n",
    "<img src=\"https://github.com/Minyall/sc207_materials/blob/master/images/tweepy.jpg?raw=true\" align=\"right\" width=\"300\">\n",
    "\n",
    "\n",
    "What kinds of exploratory analysis can we run on social media data? This session covers various examples of the kinds of insights that can be gathered through the analysis of social media data, and how to present those results.\n",
    "\n",
    "[Tweepy Documentation](http://docs.tweepy.org/en/stable/)\n",
    "\n",
    "## Section a) Unpacking your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def pandas_find_first_retweet(df):\n",
    "    rt_filter = ~df.retweeted_status.isna()\n",
    "    return df[rt_filter].iloc[0].copy()  \n",
    "def show_df_breakpoint(df,original_df_len):\n",
    "    return df.iloc[original_df_len-3:original_df_len+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('example_twitter_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the .info() to see an overview of our data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Extracting Original Tweets\n",
    "\n",
    "Remember, retweeted statuses contain the data of the original tweet as well. If your project would benefit from increasing the amount of data further, or you want to include Tweets that may be older than the window in which you sampled data, then extracting retweets may be a useful technique for you.\n",
    "Some projects may not need the retweets extracted - for example if you specifically wanted to only examine activity from the period when you sampled.\n",
    "\n",
    "##### Presuming we do want to extract them...\n",
    "If we first look at one row in our DataFrame that represents a retweet that contains the original material posted..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_retweet = pandas_find_first_retweet(df)\n",
    "example_retweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and we examine the `retweeted_status` column, we can see that it contains a dictionary of the original tweet, just like the ones we originally built the dataset with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the retweeted_status of our example_retweet\n",
    "example_retweet['retweeted_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know we have the data in a structure that we can use... in general our steps are...\n",
    " 1. Filter the dataframe so we are only selecting rows that have retweet data.\n",
    " 2. Turn the `retweeted_status` column into a simple list such that it is a list of dictionaries, like we originally had when we first made the dataframe.\n",
    " 3. Turn that list of dictionaries into a DataFrame, and then add it to our existing data\n",
    " 4. Drop any duplicates (we may already have collected a tweet that was also retweeted)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's see how long our DF is so we can see the difference...\n",
    "original_df_length = len(df)\n",
    "original_df_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter the data\n",
    "\n",
    "rt_filter = ~df['retweeted_status'].isna()\n",
    "retweets = df[rt_filter]['retweeted_status']\n",
    "retweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the column into a list of dictionaries\n",
    "\n",
    "retweet_list = retweets.to_list()\n",
    "\n",
    "# at this point we can check how many retweets we have\n",
    "print(len(retweet_list))\n",
    "\n",
    "retweet_list[:1] # if we examine the first item we can see that we have our list of dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Turn it into a DataFrame and add it to our existing data\n",
    "retweet_df = pd.DataFrame(retweet_list)\n",
    "df = df.append(retweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_df_length)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Drop any duplicates\n",
    "df = df.drop_duplicates('id')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we reset the index. Why? \n",
    "- Because we've stuck two DataFrames together, each with their own indexes running from 0 to however long they are. By appending one to the other we now have rows with the same index name...\n",
    "- Because dropping duplicates doesn't reset the index, so there will be holes in our dataframe index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a custom function built for teaching purposes (you can see how it works at the beginning of the notebook)\n",
    "show_df_breakpoint(df,original_df_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check this by checking the .info() See the mismatch...\n",
    "> Int64Index: ....\n",
    "\n",
    "How can the index be shorter than the number of entries we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the info for discrepancies between records and index length\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a broken index like this will cause problems, so we `.reset_index(drop=True)`. Drop means to completely forget the original index - otherwise it gets added as another column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck the info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with much of what we do, we've broken the above into steps to better explain it, however it could reasonably be done in a few lines..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the filter\n",
    "rt_filter = ~df['retweeted_status'].isna()\n",
    "\n",
    "#filter the dataframe, convert the retweeted_status columnn to a list and wrap it in a new dataframe\n",
    "retweet_df = pd.DataFrame( df[rt_filter]['retweeted_status'].tolist() )\n",
    "\n",
    "# append the new dataframe to the original, drop duplicates and reset the index\n",
    "df = df.append(retweet_df).drop_duplicates('id').reset_index(drop=True)\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could even turn this into a function...\n",
    "\n",
    "# name the function extract_original_tweets\n",
    "\n",
    "def extract_original_tweets(df):\n",
    "    rt_filter = ~df['retweeted_status'].isna()\n",
    "    retweet_df = pd.DataFrame( df[rt_filter]['retweeted_status'].tolist() )\n",
    "    df = df.append(retweet_df).drop_duplicates('id').reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we reload from disk to reset everything we can see if our function works\n",
    "df = pd.read_pickle('example_twitter_data.pkl')\n",
    "print(len(df))\n",
    "\n",
    "df = extract_original_tweets(df)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Unpacking Nested Data\n",
    "Some of our other columns contain nested data, such as our user column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0,'user']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst there are a variety of ways to do this, and we could just unpack the columns we need, it is ultimately simpler to unpack everything with two commands.\n",
    "- `.to_dict(orient='records')` translates a dataframe into a list of dictionaries, each containing their own nested dictionaries\n",
    "- `pd.json_normalize` can create a Dataframe from a list of dictionaries, and flattens out nested dictionaries into their own columns.\n",
    "\n",
    "This will take a while, but worth doing once after extracting all retweets, and then saving to disk and working with the fully 'blown-up' dataframe from then on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dicts = df.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe using json_normalize on the list of dictionaries\n",
    "df = pd.json_normalize(df_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the info, we might need to set some arguments\n",
    "df.info(verbose=True,null_counts=True)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our uinpacked version to a new pickle file\n",
    "\n",
    "df.to_pickle('example_twitter_data_unpacked.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:teaching]",
   "language": "python",
   "name": "conda-env-teaching-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
