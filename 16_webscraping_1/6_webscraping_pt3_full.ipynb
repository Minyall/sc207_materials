{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebScraping\n",
    "## 3. Extracting all rows on multiple pages\n",
    "Now we can ask requests to retrieve a page, feed it to our function, and recieve a structured list of relevant information. Now let's repeat this across multiple pages on the forum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating here to ensure everyone has the same functions\n",
    "def row_info_extractor(row): # We'll feed it the isolated html for a row and let it pull it apart.\n",
    "    author = row['data-author']\n",
    "    \n",
    "    id_item = row['class'][-1]\n",
    "    thread_id = int(id_item.split('-')[-1])\n",
    "    \n",
    "    title_div = row.find('div', class_='structItem-title')\n",
    "    title = title_div.a.text.strip() # remember to .strip() off the useless spaces on the ends.\n",
    "    \n",
    "    date = row.find('time')['datetime']\n",
    "    \n",
    "    views = row.find('dl',class_='pairs pairs--justified structItem-minor').dd.text\n",
    "\n",
    "    relative_url = title_div.a['href']\n",
    "    full_url = urllib.parse.urljoin('http://uberpeople.net',relative_url)\n",
    "    \n",
    "    data_package = {'id': thread_id,\n",
    "                  'author': author,\n",
    "                  'title': title,\n",
    "                  'date': date,\n",
    "                  'views': views,\n",
    "                  'url': full_url}\n",
    "    \n",
    "    return data_package\n",
    "\n",
    "def page_info_extractor(response):\n",
    "    soup = BeautifulSoup(response.text,'lxml')\n",
    "    threads_container = soup.find('div', class_=\"structItemContainer\")\n",
    "    threads = threads_container.find_all('div',class_='structItem--thread')\n",
    "    \n",
    "    page_data = []\n",
    "    for row in threads:\n",
    "        result = row_info_extractor(row)\n",
    "        page_data.append(result)\n",
    "    return page_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the page structure\n",
    "- Look at page 2 of the threads.\n",
    "- Note the url https://uberpeople.net/forums/Tips/page-2\n",
    "- https://uberpeople.net/forums/Tips/page-1 takes us back to our original first page\n",
    "- Does this link work https://uberpeople.net/forums/Tips/page-300 ?\n",
    "- We can also see various points where the page provides us information on how many pages there are in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visiting multiple pages automatically\n",
    "We could, as we have above, manually create a new response object for each page, but that's not what programming is all about! How then do we automate the process.\n",
    "\n",
    "- We already know that we can predict the url for the any page of threads because it has the same structure `https://uberpeople.net/forums/Tips/page-{pick a number}`\n",
    "- This means we just need to increment that number by 1 every time we want to move to a new page.\n",
    "- Let's begin by working out how to generate urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# the built in range function is an iterator that outputs numbers based on certain criteria\n",
    "\n",
    "# up to BUT NOT INCLUDING 5, note that by default range starts at 0\n",
    "for number in range(5):\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# we can set a start number \n",
    "for number in range(1,5):\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://uberpeople.net/forums/Tips/page-1\n",
      "https://uberpeople.net/forums/Tips/page-2\n",
      "https://uberpeople.net/forums/Tips/page-3\n",
      "https://uberpeople.net/forums/Tips/page-4\n",
      "https://uberpeople.net/forums/Tips/page-5\n"
     ]
    }
   ],
   "source": [
    "# how do we use this for our job?\n",
    "\n",
    "maximum_pages = 5\n",
    "\n",
    "for number in range(1, maximum_pages+1): #we do +1 so it actually outputs up to AND INCLUDING the number we set as our maximum.\n",
    "    url = f'https://uberpeople.net/forums/Tips/page-{number}' # f-strings allows us to easily insert values into strings.\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets break down the steps\n",
    "\n",
    "# We set out maximum number of pages so we don't lose control!\n",
    "max_page = 3\n",
    "\n",
    "# We create an empty list to contain all the results from every page\n",
    "\n",
    "data = []\n",
    "\n",
    "# We create our range generator that spits out numbers between 1 and our maximum number of pages\n",
    "for page_no in range(1, max_page+1):\n",
    "    \n",
    "    # build the url\n",
    "    url = f'https://uberpeople.net/forums/Tips/page-{page_no}'\n",
    "    \n",
    "    # retrieve the page\n",
    "    response = requests.get(url)\n",
    "    page_data = page_info_extractor(response)\n",
    "    \n",
    "    # we EXTEND the final data list with our results and the loop starts from the beginning to collect the next set\n",
    "    data.extend(page_data) # \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 360062,\n",
       " 'author': 'Tolerate_Nonsense',\n",
       " 'title': 'Make money before they deactivate you.',\n",
       " 'date': '2019-11-03T05:44:37-0800',\n",
       " 'views': '1K',\n",
       " 'url': 'http://uberpeople.net/threads/make-money-before-they-deactivate-you.360062/'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethical Scraping\n",
    "Web Scraping uses the resources of the websites that we draw data from. Scripted scrapers can access these resources much faster than the site would expect a user to 'browse' the site. Some sites will even block connections from computers that they believe are displaying unusual browsing activity.\n",
    "\n",
    "Therefore from an ethical and practical perspective it is important not to simply run the script at full speed, but to artificially slow it down a little.\n",
    "\n",
    "We can also use this opportunity to provide ourselves with a little more insight into what is going on in the script as it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now retrieving page 1\n",
      "Waiting 2 seconds...\n",
      "Now retrieving page 2\n",
      "Waiting 5 seconds...\n",
      "Now retrieving page 3\n",
      "Waiting 4 seconds...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "max_page = 3\n",
    "data = []\n",
    "for page_no in range(1, max_page+1):\n",
    "    print(f'Now retrieving page {page_no}')\n",
    "    \n",
    "    url = f'https://uberpeople.net/forums/Tips/page-{page_no}'\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    page_data = page_info_extractor(response)\n",
    "    \n",
    "    data.extend(page_data)\n",
    "    \n",
    "    wait_time = randint(2,8) # randomly select an integer between 2 and 8\n",
    "    print(f'Waiting {wait_time} seconds...')\n",
    "    \n",
    "    sleep(wait_time)\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tolerate_Nonsense</td>\n",
       "      <td>2019-11-03T05:44:37-0800</td>\n",
       "      <td>360062</td>\n",
       "      <td>Make money before they deactivate you.</td>\n",
       "      <td>http://uberpeople.net/threads/make-money-befor...</td>\n",
       "      <td>1K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WNYuber</td>\n",
       "      <td>2019-11-04T13:26:42-0800</td>\n",
       "      <td>360311</td>\n",
       "      <td>Finally, we can thank our riders!</td>\n",
       "      <td>http://uberpeople.net/threads/finally-we-can-t...</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mkang14</td>\n",
       "      <td>2019-11-02T02:10:37-0700</td>\n",
       "      <td>359881</td>\n",
       "      <td>Should Women Drive After MidNight?</td>\n",
       "      <td>http://uberpeople.net/threads/should-women-dri...</td>\n",
       "      <td>2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>am_gh22</td>\n",
       "      <td>2019-11-05T06:55:04-0800</td>\n",
       "      <td>360460</td>\n",
       "      <td>How do you deal with these pax?</td>\n",
       "      <td>http://uberpeople.net/threads/how-do-you-deal-...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codyco1221</td>\n",
       "      <td>2019-11-05T03:01:36-0800</td>\n",
       "      <td>360424</td>\n",
       "      <td>Rush hour</td>\n",
       "      <td>http://uberpeople.net/threads/rush-hour.360424/</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                      date      id  \\\n",
       "0  Tolerate_Nonsense  2019-11-03T05:44:37-0800  360062   \n",
       "1            WNYuber  2019-11-04T13:26:42-0800  360311   \n",
       "2            Mkang14  2019-11-02T02:10:37-0700  359881   \n",
       "3            am_gh22  2019-11-05T06:55:04-0800  360460   \n",
       "4         codyco1221  2019-11-05T03:01:36-0800  360424   \n",
       "\n",
       "                                    title  \\\n",
       "0  Make money before they deactivate you.   \n",
       "1       Finally, we can thank our riders!   \n",
       "2      Should Women Drive After MidNight?   \n",
       "3         How do you deal with these pax?   \n",
       "4                               Rush hour   \n",
       "\n",
       "                                                 url views  \n",
       "0  http://uberpeople.net/threads/make-money-befor...    1K  \n",
       "1  http://uberpeople.net/threads/finally-we-can-t...   886  \n",
       "2  http://uberpeople.net/threads/should-women-dri...    2K  \n",
       "3  http://uberpeople.net/threads/how-do-you-deal-...    49  \n",
       "4    http://uberpeople.net/threads/rush-hour.360424/    52  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tolerate_Nonsense</td>\n",
       "      <td>2019-11-03 13:44:37</td>\n",
       "      <td>360062</td>\n",
       "      <td>Make money before they deactivate you.</td>\n",
       "      <td>http://uberpeople.net/threads/make-money-befor...</td>\n",
       "      <td>1K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WNYuber</td>\n",
       "      <td>2019-11-04 21:26:42</td>\n",
       "      <td>360311</td>\n",
       "      <td>Finally, we can thank our riders!</td>\n",
       "      <td>http://uberpeople.net/threads/finally-we-can-t...</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mkang14</td>\n",
       "      <td>2019-11-02 09:10:37</td>\n",
       "      <td>359881</td>\n",
       "      <td>Should Women Drive After MidNight?</td>\n",
       "      <td>http://uberpeople.net/threads/should-women-dri...</td>\n",
       "      <td>2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>am_gh22</td>\n",
       "      <td>2019-11-05 14:55:04</td>\n",
       "      <td>360460</td>\n",
       "      <td>How do you deal with these pax?</td>\n",
       "      <td>http://uberpeople.net/threads/how-do-you-deal-...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codyco1221</td>\n",
       "      <td>2019-11-05 11:01:36</td>\n",
       "      <td>360424</td>\n",
       "      <td>Rush hour</td>\n",
       "      <td>http://uberpeople.net/threads/rush-hour.360424/</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                date      id  \\\n",
       "0  Tolerate_Nonsense 2019-11-03 13:44:37  360062   \n",
       "1            WNYuber 2019-11-04 21:26:42  360311   \n",
       "2            Mkang14 2019-11-02 09:10:37  359881   \n",
       "3            am_gh22 2019-11-05 14:55:04  360460   \n",
       "4         codyco1221 2019-11-05 11:01:36  360424   \n",
       "\n",
       "                                    title  \\\n",
       "0  Make money before they deactivate you.   \n",
       "1       Finally, we can thank our riders!   \n",
       "2      Should Women Drive After MidNight?   \n",
       "3         How do you deal with these pax?   \n",
       "4                               Rush hour   \n",
       "\n",
       "                                                 url views  \n",
       "0  http://uberpeople.net/threads/make-money-befor...    1K  \n",
       "1  http://uberpeople.net/threads/finally-we-can-t...   886  \n",
       "2  http://uberpeople.net/threads/should-women-dri...    2K  \n",
       "3  http://uberpeople.net/threads/how-do-you-deal-...    49  \n",
       "4    http://uberpeople.net/threads/rush-hour.360424/    52  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is an opportunity for us to also clean up our date column and our views column\n",
    "\n",
    "# We can quickly transform the date column from a set of strings into date objects...\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_fixer(view_string):\n",
    "    view_string = view_string.replace('K','000')\n",
    "    view_integer = int(view_string)\n",
    "    return view_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# test our function\n",
    "\n",
    "print(view_fixer(\"2K\"))\n",
    "print(view_fixer(\"500\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1000\n",
       "1      886\n",
       "2     2000\n",
       "3       49\n",
       "4       52\n",
       "5      420\n",
       "6      304\n",
       "7       46\n",
       "8      663\n",
       "9       10\n",
       "10     107\n",
       "11    4000\n",
       "12     148\n",
       "13    5000\n",
       "14     250\n",
       "15     125\n",
       "16     210\n",
       "17    3000\n",
       "18     102\n",
       "19    1000\n",
       "20     271\n",
       "21     222\n",
       "22     427\n",
       "23     774\n",
       "24     126\n",
       "25      57\n",
       "26      58\n",
       "27      45\n",
       "28      69\n",
       "29     142\n",
       "30    2000\n",
       "31     212\n",
       "32    3000\n",
       "33     126\n",
       "34      68\n",
       "35      71\n",
       "36     508\n",
       "37     333\n",
       "38      93\n",
       "39      89\n",
       "40     428\n",
       "41    3000\n",
       "42     194\n",
       "43      67\n",
       "44     122\n",
       "45     236\n",
       "46     116\n",
       "47      81\n",
       "48     160\n",
       "49      68\n",
       "50      62\n",
       "51    5000\n",
       "52     112\n",
       "53     485\n",
       "54     471\n",
       "55     434\n",
       "56    3000\n",
       "57     935\n",
       "58    2000\n",
       "59     233\n",
       "Name: views, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we cann apply this function to every row of the view column\n",
    "df['views'].apply(view_fixer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... and simply overwrite the views column with the result\n",
    "df['views'] = df['views'].apply(view_fixer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tolerate_Nonsense</td>\n",
       "      <td>2019-11-03 13:44:37</td>\n",
       "      <td>360062</td>\n",
       "      <td>Make money before they deactivate you.</td>\n",
       "      <td>http://uberpeople.net/threads/make-money-befor...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WNYuber</td>\n",
       "      <td>2019-11-04 21:26:42</td>\n",
       "      <td>360311</td>\n",
       "      <td>Finally, we can thank our riders!</td>\n",
       "      <td>http://uberpeople.net/threads/finally-we-can-t...</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mkang14</td>\n",
       "      <td>2019-11-02 09:10:37</td>\n",
       "      <td>359881</td>\n",
       "      <td>Should Women Drive After MidNight?</td>\n",
       "      <td>http://uberpeople.net/threads/should-women-dri...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>am_gh22</td>\n",
       "      <td>2019-11-05 14:55:04</td>\n",
       "      <td>360460</td>\n",
       "      <td>How do you deal with these pax?</td>\n",
       "      <td>http://uberpeople.net/threads/how-do-you-deal-...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codyco1221</td>\n",
       "      <td>2019-11-05 11:01:36</td>\n",
       "      <td>360424</td>\n",
       "      <td>Rush hour</td>\n",
       "      <td>http://uberpeople.net/threads/rush-hour.360424/</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                date      id  \\\n",
       "0  Tolerate_Nonsense 2019-11-03 13:44:37  360062   \n",
       "1            WNYuber 2019-11-04 21:26:42  360311   \n",
       "2            Mkang14 2019-11-02 09:10:37  359881   \n",
       "3            am_gh22 2019-11-05 14:55:04  360460   \n",
       "4         codyco1221 2019-11-05 11:01:36  360424   \n",
       "\n",
       "                                    title  \\\n",
       "0  Make money before they deactivate you.   \n",
       "1       Finally, we can thank our riders!   \n",
       "2      Should Women Drive After MidNight?   \n",
       "3         How do you deal with these pax?   \n",
       "4                               Rush hour   \n",
       "\n",
       "                                                 url  views  \n",
       "0  http://uberpeople.net/threads/make-money-befor...   1000  \n",
       "1  http://uberpeople.net/threads/finally-we-can-t...    886  \n",
       "2  http://uberpeople.net/threads/should-women-dri...   2000  \n",
       "3  http://uberpeople.net/threads/how-do-you-deal-...     49  \n",
       "4    http://uberpeople.net/threads/rush-hour.360424/     52  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we save our dataframe for the next stage\n",
    "#Pickle files save things EXACTLY as you have them here. \n",
    "# Saving as a CSV converts data into different types, for example all our datetime objects will become strings,\n",
    "# We use pickle to preserve the dataframe as it is. Be warned however, pickling\n",
    "# is very reliant on having the exact same version of pandas so it's best to only use pickle to store data\n",
    "# between stages on the same computer\n",
    "\n",
    "df.to_pickle('my_uber_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:teaching]",
   "language": "python",
   "name": "conda-env-teaching-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
