{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebScraping\n",
    "## 5. Retrieving Thread Content (Multi-Page)\n",
    "We'll continue working with this thread as our multi-page thread...\n",
    "\n",
    "https://uberpeople.net/threads/fight-for-equity-in-uber-not-to-become-an-employee.30393/\n",
    "\n",
    "Let's compare it with this single page thread\n",
    "\n",
    "https://uberpeople.net/threads/will-my-no-shave-november-beard-screw-up-ubers-facial-recognition-software.219274/\n",
    "\n",
    "- The multi-page thread has additional buttons just under the thread title to navigate thread pages, whilst the single page doesn't.\n",
    "    - We can use this to programmatically determine whether we need to be approaching a thread as a single page, or as multiple pages of content.\n",
    "- If we click on one of the page buttons and check the url we can see that similarly to the threads pages earlier, we could iterate through the pages of a single thread by just incrementing the number at the end of the url.\n",
    "- However this relies on having a site structure that operates logically like this...\n",
    "- What if there was no way to guess what the nexrt page URL is!?\n",
    "- So long as a website lets a normal user navigate to the next page, we can too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "\n",
    "def text_extractor(post):\n",
    "    post_content = post.find('article', class_='message-body')\n",
    "    quotes = post_content.find_all('blockquote', class_='bbCodeBlock--quote') \n",
    "    \n",
    "    if quotes is not None: \n",
    "        for quote in quotes:\n",
    "            quote.decompose()\n",
    "    return post_content.text.strip()\n",
    "\n",
    "def page_posts_extractor(response):\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    post_container = soup.find('div', class_='p-body-content')\n",
    "    posts = post_container.find_all('article', class_='message')\n",
    "    texts = []\n",
    "    for post in posts:\n",
    "        extracted = text_extractor(post)\n",
    "        texts.append(extracted)\n",
    "    return texts\n",
    "\n",
    "single_page_url = 'https://uberpeople.net/threads/will-my-no-shave-november-beard-screw-up-ubers-facial-recognition-software.219274/'\n",
    "multi_page_url = 'https://uberpeople.net/threads/fight-for-equity-in-uber-not-to-become-an-employee.30393/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting single or multi-page\n",
    "- Like before when we detected the presence or abscence of a quote, we can use `.find` to look for the Next button. If `.find` returns None we've got a single page thread, if not, we've got a multi-page.\n",
    "- We can also use the presence of the 'Next' button to provide us with the url of the next page.\n",
    "- Due to the design of the page it is a little tricky to safely determine what the last page is...\n",
    "    - The number of navigation buttons changes dependeing on the number of pages.\n",
    "    - The navigation buttons have similar classes.\n",
    "- However whenever there are multiple pages there is always a 'Next' button so long as there is an additional page of posts.\n",
    "- The next button will always contain the url of the 'next' page of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITHOUT a next button...\n",
    "response = requests.get(single_page_url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "next_button = soup.find('a', class_='pageNav-jump--next')\n",
    "next_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH a next button\n",
    "response = requests.get(multi_page_url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "next_button = soup.find('a', class_='pageNav-jump--next')\n",
    "next_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we can retrieve the url of the next page\n",
    "next_button['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We can build a function that tests if a page has a next button or not\n",
    "\n",
    "def get_next_url(response):\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    next_button = soup.find('a', class_='pageNav-jump--next')\n",
    "    if next_button == None:\n",
    "        result = None\n",
    "    else: \n",
    "        result = next_button['href']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_page_response = requests.get(single_page_url)\n",
    "multi_page_response = requests.get(multi_page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next_url(multi_page_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can then be used to build our full next url. Here we demonstrate why urllib.parse.urljoin is so useful..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://uberpeople.net/threads/worst-rider-experience-now-what.216997/'\n",
    "response = requests.get(url)\n",
    "next_url = get_next_url(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that to some extent the new url and the old url overlap. Compapre the two approaches of using simple string concatenation and using `urllib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url + next_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.parse.urljoin(url, next_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping until there's no 'Next'\n",
    "Essentially the stages of our scraper should be something like...\n",
    "1.  Open a thread page\n",
    "2.  Gather the text from each post\n",
    "3.  Attempt to get the next url from the next button.\n",
    "    1.  If there is a next url, repeat from 1 with the new url\n",
    "4. Finish scraping\n",
    "\n",
    "- In theory the script would loop infinitely until there is no more 'next' button. We don't need to tell it how many times to loop, simply to check for a condition.\n",
    "\n",
    "- To do this we use a `while` loop.\n",
    "- `while` loops continue repeating the same code so long as a condition is `True`. The loop stops if the condition becomes `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 0\n",
    "condition = number < 5 \n",
    "\n",
    "condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 0\n",
    "condition = True \n",
    "\n",
    "while condition:\n",
    "    number += 1\n",
    "    condition = number < 5 \n",
    "    print(f\"Condition: {number} < 5: {condition}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try this with a thread\n",
    "\n",
    "original_url = 'https://uberpeople.net/threads/worst-rider-experience-now-what.216997/' # we want to keep the original thread url for use later\n",
    "url = original_url # for the first loop of the code we need to pass it a url, the code will overwrite this variable later, but leave original_url alone.\n",
    "\n",
    "condition = True # we set our condition as True to get the loop going\n",
    "\n",
    "while condition:\n",
    "    response = requests.get(url) # use the url variable currently in memory\n",
    "    print(f\"Current URL is: {response.url}\") # print the url we're currently using\n",
    "    \n",
    "    next_url = get_next_url(response)\n",
    "    \n",
    "    if next_url is not None: # if there is a next url...\n",
    "        url = urllib.parse.urljoin(original_url,next_url) # overwrite the url variable with the url from the next button\n",
    "        # return to the beginning of the loop with the new url in memory\n",
    "        \n",
    "    else: # however if there is no next button...\n",
    "        condition = False #set condition to False\n",
    "        # The code will return to the beginning of the loop, the while loop will see that condition is False, and stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all we need now is to set this up with our posts_extractor so that every loop the text from the page\n",
    "# is extracted and added to a list that sits OUTSIDE the loop\n",
    "\n",
    "\n",
    "original_url = 'https://uberpeople.net/threads/worst-rider-experience-now-what.216997/' # we want to keep the original thread url for use later\n",
    "url = original_url # for the first loop of the code we need to pass it a url, the code will overwrite this variable later, but leave original_url alone\n",
    "thread_text_data = []\n",
    "condition = True # we set our condition as True to get the loop going\n",
    "\n",
    "while condition:\n",
    "    response = requests.get(url) # use the url variable currently in memory\n",
    "    print(f\"Current URL is: {response.url}\") # print the url we're currently using\n",
    "    \n",
    "    ### NEW BIT\n",
    "    post_texts = page_posts_extractor(response)\n",
    "    thread_text_data.extend(post_texts)\n",
    "    ### \n",
    "    \n",
    "    next_url = get_next_url(response)\n",
    "    \n",
    "    if next_url is not None: # if there is a next url...\n",
    "        url = urllib.parse.urljoin(original_url,next_url) # overwrite the url variable with the url from the next button\n",
    "        # return to the beginning of the loop with the new url in memory\n",
    "        \n",
    "    else: # however if there is no next button...\n",
    "        condition = False #set condition to False\n",
    "        # The code will return to the beginning of the loop, the while loop will see that condition is False, and stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(thread_text_data))\n",
    "print(thread_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_text = '\\n\\n****\\n\\n'.join(thread_text_data)\n",
    "print(thread_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTIVITY: Build a thread_post_extractor\n",
    "We need a function that will...\n",
    "- Take a url (not a requests response)\n",
    "- Uses a loop that will run so long as the page has a 'next' button\n",
    "- Will extract the text from all the posts \n",
    "- Will attempt to retrieve the url of the next page in the thread\n",
    "    - If the next url is present the function will overwrite the url with the url of the next page and loop back to the start again.\n",
    "    - If the next url is not present the function will end the loop and return the collected post text as a single string with posts seperated by a newline.\n",
    "- Make sure you use our two functions `page_posts_extractor()` and `get_next_url()`\n",
    "- The function should return a single string of post texts, seperated by **//**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread_post_extractor(url):\n",
    "    \n",
    "    thread_text_data = []\n",
    "    original_url = url\n",
    "    condition = True\n",
    "\n",
    "    while condition:\n",
    "        response = requests.get(url) # use the url variable currently in memory\n",
    "        print(response.url)\n",
    "\n",
    "        post_texts = page_posts_extractor(response)\n",
    "        thread_text_data.extend(post_texts)\n",
    "\n",
    "        next_url = get_next_url(response)\n",
    "\n",
    "        if next_url is not None: # if there is a next url...\n",
    "            url = urllib.parse.urljoin(original_url,next_url) # overwrite the url variable with the url from the next button\n",
    "            # return to the beginning of the loop with the new url in memory\n",
    "\n",
    "        else: # however if there is no next button...\n",
    "            condition = False #set condition to False\n",
    "    thread_text = '\\n\\n****\\n\\n'.join(thread_text_data)\n",
    "    return thread_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_page_url = 'https://uberpeople.net/threads/will-my-no-shave-november-beard-screw-up-ubers-facial-recognition-software.219274/'\n",
    "multi_page_url = 'https://uberpeople.net/threads/worst-rider-experience-now-what.216997/'\n",
    "\n",
    "single_text = thread_post_extractor(single_page_url)\n",
    "multi_text = thread_post_extractor(multi_page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(single_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multi_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:teaching]",
   "language": "python",
   "name": "conda-env-teaching-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
